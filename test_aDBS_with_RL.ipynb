{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO, SAC, DDPG\n",
    "from environment.utils import generate_w0_with_locus\n",
    "from aDBS_RL.evaluate_HF_DBS import make_env, evaluate_hf_dbs\n",
    "\n",
    "# We import env version \n",
    "from environment.env_configs.env1 import (\n",
    "    n_neurons, grid_size, coord_modif,\n",
    "    eval_envs_list, checking\n",
    ")\n",
    "np.random.seed(228)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load aDBS agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'saved_agents'\n",
    "model_name = 'ppo_R1_1000000.tf'\n",
    "model_path = os.path.join(DIR, model_name)\n",
    "\n",
    "# Load the model\n",
    "model = PPO.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set testing environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_ENV = 5\n",
    "each_env_run_episodes = 2\n",
    "\n",
    "# Instantiate environments for evaluation\n",
    "eval_envs_list_new = []\n",
    "for n_env in range(NUMBER_OF_ENV):\n",
    "    eval_d = eval_envs_list[n_env]\n",
    "\n",
    "    (w0_eval, ncoords, ngrid,\n",
    "        w0_temp_eval, w_locus_eval, lmask_eval) = generate_w0_with_locus(\n",
    "                n_neurons, grid_size,\n",
    "                coord_modif,\n",
    "                locus_center=eval_d['locus_center'],\n",
    "                locus_size=eval_d['locus_size'],\n",
    "                wmuL=17, wsdL=1, \n",
    "                show=False, vertical_layer=4)\n",
    "    \n",
    "    eval_d['reward_func'] = 'bbpow_action'\n",
    "    eval_d['neur_coords'] = ncoords\n",
    "    eval_d['neur_grid'] = ngrid\n",
    "\n",
    "    eval_d['w0'] = w0_eval\n",
    "    eval_d['w0_without_locus'] = w0_temp_eval\n",
    "    eval_d['locus_without_w0'] = w_locus_eval\n",
    "    eval_d['locus_mask'] = lmask_eval\n",
    "\n",
    "    eval_d['dbs_action_bounds'] = [-5, 5]    # NOTE: IMPORTANT!!!!\n",
    "    \n",
    "    eval_envs_list_new.append(make_env(eval_d))\n",
    "envs_cpu = eval_envs_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all info about testing environments\n",
    "print('^^'*30)\n",
    "print('THE ENVIROMENT IS:', checking)\n",
    "print('NUMBER OF ENVS:', NUMBER_OF_ENV)\n",
    "print('Each env with run for: ', each_env_run_episodes, ' times')\n",
    "\n",
    "# print('MODEL PREDICT: ', model.predict(np.ones(5)))\n",
    "print('SCALE TO INSIDE env', envs_cpu[0].params_dict['dbs_action_bounds'])\n",
    "print('Episode len:', envs_cpu[0].params_dict['total_episode_len'])\n",
    "\n",
    "print('Temporal drift:', envs_cpu[0].params_dict['temporal_drift'])\n",
    "print('Spatial features:', envs_cpu[0].params_dict['spatial_feature'])\n",
    "print('^^'*30)\n",
    "r = envs_cpu[0].params_dict['dbs_action_bounds'][1]\n",
    "print('Energy is = ',\n",
    "    f'e * {r} / {each_env_run_episodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbpow_mean, bbpow_sd, e_mean, e_sd = evaluate_hf_dbs(model, envs_cpu,\n",
    "                \n",
    "                # NOTE: IMPORTANT: EACH environment run this num of episodes\n",
    "                n_eval_episodes=each_env_run_episodes, \n",
    "\n",
    "                render=False, deterministic=True,\n",
    "                warn=False, callbacks_=None)\n",
    "true_energy = e_mean * envs_cpu[0].params_dict['dbs_action_bounds'][1] / each_env_run_episodes\n",
    "true_energy_sd = e_sd * envs_cpu[0].params_dict['dbs_action_bounds'][1] / each_env_run_episodes\n",
    "print('Energy is = ', true_energy, ' sd= ', true_energy_sd)\n",
    "\n",
    "# Save all to file\n",
    "with open('data/eval_results.json', 'a') as f:\n",
    "    res = {'env':checking,\n",
    "            'agent': 'ppo_R1', \n",
    "            'bbpow mean':bbpow_mean,\n",
    "            'bbpow sd':bbpow_sd, \n",
    "            'energy mean':true_energy,\n",
    "            'energy sd':true_energy_sd,\n",
    "            }\n",
    "    f.write(str(res) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
